{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load data from pickle file\n",
    "df = pd.read_pickle('ehr_preprocessed_seq_by_day_cat_embedding.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91037f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1_logistic = []\n",
    "cols2_logistic = []\n",
    "cols3_logistic = []\n",
    "cols4_logistic = []\n",
    "cols5_logistic = []\n",
    "\n",
    "#Create column name\n",
    "for i in df['feature_cols']:\n",
    "    j = i + \"_avg\"\n",
    "    k = i + \"_stdev\"\n",
    "    l = i + \"_max\"\n",
    "    m = i + \"_min\"\n",
    "    n = i + \"_diff\"\n",
    "\n",
    "    cols1_logistic.append(j)\n",
    "    cols2_logistic.append(k)\n",
    "    cols3_logistic.append(l)\n",
    "    cols4_logistic.append(m)\n",
    "    cols5_logistic.append(n)\n",
    "    \n",
    "cols_logistic = ['ID']    \n",
    "cols_logistic += cols1_logistic + cols2_logistic + cols3_logistic + cols4_logistic + cols5_logistic \n",
    "cols_logistic.append('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97def11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension Reduction\n",
    "\n",
    "datalist = []\n",
    "\n",
    "for i in df['feat_dict']:\n",
    "    \n",
    "    ID = i\n",
    "    data = df['feat_dict'][i]\n",
    "    means = np.mean(data, axis=0)\n",
    "    std_devs = np.std(data, axis=0)\n",
    "    n = data.shape[0]\n",
    "    daily_changes = np.diff(data, axis=0)\n",
    "    maxs = np.max(data, axis=0)\n",
    "    mins = np.min(data, axis=0)\n",
    "    diffs = data[-1, :] - data[0, :]\n",
    "    summary_stats = np.concatenate([[ID], means, std_devs, maxs, mins, diffs, [n]])\n",
    "    datalist.append(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f9acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflogistic = pd.DataFrame(datalist, columns = cols_logistic)\n",
    "dflogistic = dflogistic.set_index('ID')\n",
    "dflogistic\n",
    "\n",
    "#Get y values for model training\n",
    "dftraindata = pd.read_csv('train.csv')\n",
    "dftraindata = dftraindata.groupby('id')['readmitted_within_30days'].mean().to_frame()\n",
    "\n",
    "dftrain = dflogistic.join(dftraindata, how='inner')\n",
    "\n",
    "#Separate to training data x and y\n",
    "dftraindata_x = dftrain[cols1_logistic + cols2_logistic + cols3_logistic + cols4_logistic + cols5_logistic + ['n']]\n",
    "dftraindata_y = dftrain['readmitted_within_30days']\n",
    "\n",
    "#Handling resampling using SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(dftraindata_x, dftraindata_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7e8106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get valid data set for model validation\n",
    "dfvaliddata = pd.read_csv('valid.csv')\n",
    "dfvaliddataid = dfvaliddata['id'].unique()\n",
    "dfvaliddata_x = dflogistic.loc[dfvaliddataid]\n",
    "dfvaliddata_x.sort_values(by=['ID'], inplace=True)\n",
    "\n",
    "\n",
    "#Separate to valid data x and y\n",
    "dfvaliddata_y = dfvaliddata.groupby('id')['readmitted_within_30days'].mean().to_frame()\n",
    "dfvaliddata_y.sort_values(by=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1\n",
    "# Create a Random Forest model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=400, random_state=42)\n",
    "\n",
    "# Fit the model to your data\n",
    "clf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f5ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = dfvaliddata_x[cols1_logistic + cols2_logistic + cols3_logistic + cols4_logistic + cols5_logistic + ['n']]\n",
    "\n",
    "#Run model on valid data\n",
    "predict = clf.predict(X_valid)\n",
    "predict\n",
    "validprob = clf.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb432f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Assuming `dftestdata_y` is your true labels\n",
    "y_true = dfvaliddata_y\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = metrics.accuracy_score(dfvaliddata_y, predict)\n",
    "precision = metrics.precision_score(dfvaliddata_y, predict)\n",
    "recall = metrics.recall_score(dfvaliddata_y, predict)\n",
    "f1_score = metrics.f1_score(dfvaliddata_y, predict)\n",
    "auc = metrics.roc_auc_score(dfvaliddata_y, validprob)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"ROC AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafab5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate FPR, TPR for the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(dfvaliddata_y, validprob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8777aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take in test data\n",
    "dftestdata = pd.read_csv('test.csv')\n",
    "dftestdataid = dftestdata['id'].unique()\n",
    "dftestdata_x = dflogistic.loc[dftestdataid]\n",
    "#dftestdata_x\n",
    "dftestdata_x.sort_values(by=['ID'], inplace=True)\n",
    "\n",
    "\n",
    "#Run model on test data\n",
    "X_test = dftestdata_x[cols1_logistic + cols2_logistic + cols3_logistic + cols4_logistic + cols5_logistic + ['n']]\n",
    "testprob = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7122e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31066b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['readmitted_within_30days'] = testprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f958ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['readmitted_within_30days'].to_csv(\"result.csv\", float_format='%.7f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
